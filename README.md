# ğŸš€ Ad Campaign Spend Tracker

A comprehensive **Data Engineering Portfolio Project** demonstrating end-to-end data pipeline development, from data generation to business intelligence.

## ğŸ“Š Project Overview

This project simulates a real-world **Ad Campaign Analytics** system, processing data from multiple advertising platforms (Google, Facebook, LinkedIn, TikTok, Twitter) to provide actionable insights for marketing teams.

### ğŸ¯ **Portfolio Highlights**

- **End-to-End Data Pipeline**: Airflow â†’ Snowflake â†’ dbt â†’ Analytics
- **Real Business Intelligence**: 4.58B impressions, $109.6M spend analysis
- **Professional Star Schema**: Kimball methodology implementation with visual diagrams
- **Data Quality Assurance**: Great Expectations + PyTest testing
- **Modern Data Stack**: Airflow, Snowflake, dbt, Python, Qlik Sense
- **Production-Ready Code**: Comprehensive testing, documentation, error handling
- **Advanced Orchestration**: Master DAG with email alerts & monitoring
- **Professional Visualizations**: DAG graphs, star schema diagrams, dashboard mockups

## ğŸ—ï¸ Architecture

### ğŸŒŸ **Star Schema Data Model**

Our data architecture follows the **Kimball Star Schema** methodology, featuring:

- **1 Fact Table**: `FACT_CAMPAIGN_PERFORMANCE` - Central hub for all metrics
- **6 Dimension Tables**: Campaigns, Platforms, Geography, Devices, Time, Ad Formats
- **Optimized Performance**: Indexed foreign keys, denormalized structure
- **Business Focus**: Aligned with marketing analytics requirements

**ğŸ“ Complete diagrams and documentation available in `star_schema_diagrams/` folder**

**ğŸš€ Generate Custom Diagrams:**
```bash
cd star_schema_diagrams/
python generate_star_schema.py
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   Apache        â”‚    â”‚   Snowflake     â”‚    â”‚   dbt           â”‚
â”‚   (Simulated)   â”‚â”€â”€â”€â–¶â”‚   Airflow       â”‚â”€â”€â”€â–¶â”‚   Data          â”‚â”€â”€â”€â–¶â”‚   Transform     â”‚
â”‚                 â”‚    â”‚   Orchestration â”‚    â”‚   Warehouse     â”‚    â”‚   & Modeling   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚                       â”‚
                                â–¼                       â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Data Quality  â”‚    â”‚   Data          â”‚    â”‚   Business      â”‚
                       â”‚   Validation    â”‚    â”‚   Retention     â”‚    â”‚   Intelligence  â”‚
                       â”‚   (Great        â”‚    â”‚   Management    â”‚    â”‚   & Analytics   â”‚
                       â”‚    Expectations)â”‚    â”‚                 â”‚    â”‚                 â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Current Data Volume

- **Total Records**: 84,000+ ad campaign records
- **Date Range**: Last 90 days (rolling retention)
- **Platforms**: Google, Facebook, LinkedIn, TikTok, Twitter
- **Geographies**: 14 major markets (US, CA, GB, DE, FR, AU, JP, IN, BR, MX, NL, IT, ES, SE)
- **Campaign Types**: 7 objectives (brand awareness, conversions, traffic, etc.)
- **Daily Volume**: 5,000 new records per day

## ğŸš€ **Project Status**

| Component | Status | Description |
|-----------|--------|-------------|
| **Data Generation** | âœ… **COMPLETE** | Realistic ad campaign data with business logic |
| **Airflow Orchestration** | âœ… **COMPLETE** | Daily pipeline with smart data management |
| **Snowflake Integration** | âœ… **COMPLETE** | Cloud data warehouse with optimized loading |
| **dbt Transformation** | âœ… **COMPLETE** | Kimball star schema with 4 marts |
| **Data Quality Testing** | âœ… **COMPLETE** | Great Expectations + PyTest suite |
| **Business Intelligence** | âœ… **COMPLETE** | Portfolio showcase queries & analytics |
| **Documentation** | âœ… **COMPLETE** | Auto-generated dbt docs & project docs |
| **Qlik Sense Dashboard** | âœ… **COMPLETE** | Complete dashboard setup & documentation |
| **Star Schema Diagrams** | âœ… **COMPLETE** | Professional diagrams & documentation |
| **DAG Visualizations** | âœ… **COMPLETE** | Airflow DAG graph images |
| **Email Alerts** | âœ… **COMPLETE** | SMTP configuration & setup |
| **Great Expectations** | âœ… **COMPLETE** | Advanced data validation |
| **Unit Testing** | âœ… **COMPLETE** | Automated test coverage |

### ğŸ¯ **Overall Project Status: 100% COMPLETE** ğŸ‰

**This project is now a comprehensive, production-ready data engineering portfolio that demonstrates:**
- âœ… **End-to-End Data Pipeline**: Complete from data generation to business intelligence
- âœ… **Professional Architecture**: Kimball methodology with optimized performance
- âœ… **Production Features**: Monitoring, alerting, testing, and documentation
- âœ… **Portfolio Ready**: Visual diagrams, DAG graphs, and complete documentation
- âœ… **Modern Data Stack**: Latest technologies and best practices

## ğŸ› ï¸ **Technology Stack**

### **Core Technologies**
- **Python 3.11+**: Data processing, API integration
- **Apache Airflow 3.0**: Workflow orchestration & DAG management
- **Snowflake**: Cloud data warehouse & data storage
- **dbt**: Data transformation & modeling (Kimball methodology)
- **Pandas**: Data manipulation & analysis
- **Qlik Sense**: Business intelligence & dashboard creation

### **Data Quality & Testing**
- **Great Expectations**: Data validation & quality assurance
- **PyTest**: Unit testing & test automation
- **Coverage**: Code coverage reporting

### **Infrastructure**
- **Virtual Environment**: Dependency management
- **Environment Variables**: Secure credential management
- **Logging**: Comprehensive pipeline monitoring
- **Email Alerts**: SMTP configuration for notifications
- **DAG Visualization**: Graphviz integration for Airflow DAGs

## ğŸ“ **Project Structure**

```
ad_campaign_spend_tracker/
â”œâ”€â”€ ğŸ“Š dags/                          # Airflow DAGs & Orchestration
â”‚   â”œâ”€â”€ ad_data_generator_dag.py     # Main pipeline orchestration
â”‚   â”œâ”€â”€ data_quality_validation_dag.py # Data quality validation
â”‚   â”œâ”€â”€ dbt_transformation_dag.py    # dbt transformation pipeline
â”‚   â”œâ”€â”€ analytics_testing_dag.py     # Analytics & testing pipeline
â”‚   â”œâ”€â”€ monitoring_alerting_dag.py   # Monitoring & alerting
â”‚   â””â”€â”€ master_portfolio_pipeline_dag.py # Master orchestration DAG
â”œâ”€â”€ ğŸ”§ scripts/                       # Data processing scripts
â”‚   â”œâ”€â”€ generate_fake_ads.py         # Daily data generation
â”‚   â”œâ”€â”€ generate_backfill_ads.py     # Historical data generation
â”‚   â”œâ”€â”€ load_backfill_to_snowflake.py # Initial data loading
â”‚   â”œâ”€â”€ load_daily_snowflake.py      # Daily incremental loading
â”‚   â””â”€â”€ data_retention_manager.py    # Data lifecycle management
â”œâ”€â”€ ğŸ—„ï¸ dbt/                          # Data transformation & modeling
â”‚   â”œâ”€â”€ models/                      # dbt models
â”‚   â”‚   â”œâ”€â”€ staging/                # Data cleaning & validation
â”‚   â”‚   â”œâ”€â”€ dimensions/             # Dimension tables
â”‚   â”‚   â””â”€â”€ marts/                  # Business intelligence marts
â”‚   â”œâ”€â”€ dbt_project.yml             # dbt configuration
â”‚   â””â”€â”€ profiles.yml                # Snowflake connection
â”œâ”€â”€ ğŸ§ª tests/                        # Test suite & coverage
â”‚   â”œâ”€â”€ test_data_generation.py     # Data generation tests
â”‚   â””â”€â”€ test_*.py                   # Additional test files
â”œâ”€â”€ ğŸ” great_expectations/           # Data quality validation
â”‚   â”œâ”€â”€ great_expectations.yml      # GE configuration
â”‚   â”œâ”€â”€ expectations/                # Data quality expectations
â”‚   â””â”€â”€ validate_ad_data.py         # Validation script
â”œâ”€â”€ ğŸŒŸ star_schema_diagrams/         # Star schema diagrams & documentation
â”‚   â”œâ”€â”€ star_schema_simple.png       # Overview diagram
â”‚   â”œâ”€â”€ star_schema_detailed.png     # Detailed field diagram
â”‚   â”œâ”€â”€ star_schema_diagram.md       # Mermaid diagram for GitHub
â”‚   â”œâ”€â”€ STAR_SCHEMA_GUIDE.md         # Complete usage guide
â”‚   â”œâ”€â”€ generate_star_schema.py      # Custom diagram generator
â”‚   â””â”€â”€ FOLDER_STRUCTURE.md          # Organization overview
â”œâ”€â”€ ğŸ¨ qlik_sense_dashboard/         # Qlik Sense dashboard setup
â”‚   â”œâ”€â”€ README.md                    # Dashboard overview
â”‚   â”œâ”€â”€ QUICK_START.md               # Quick start guide
â”‚   â”œâ”€â”€ qlik_workbook_template.md    # Step-by-step app creation
â”‚   â”œâ”€â”€ advanced_calculations.md     # Advanced Qlik expressions
â”‚   â””â”€â”€ dashboard_mockup.md          # Visual layout guide
â”œâ”€â”€ ğŸ“Š dag_visualizations/           # Airflow DAG visualizations
â”‚   â”œâ”€â”€ README.md                    # Visualization documentation
â”‚   â””â”€â”€ *.png                        # DAG graph images
â”œâ”€â”€ ğŸ“š sql/                          # SQL scripts
â”‚   â””â”€â”€ create_raw_table.sql         # Snowflake table creation
â”œâ”€â”€ ğŸ“– docs/                         # Documentation
â”‚   â””â”€â”€ PORTFOLIO_SUMMARY.md         # Project overview
â”œâ”€â”€ ğŸš€ run_portfolio_queries.py      # Analytics showcase
â”œâ”€â”€ ğŸ§ª run_tests.py                  # Test runner
â”œâ”€â”€ ğŸ“‹ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“‹ requirements-test.txt          # Testing dependencies
â”œâ”€â”€ âš™ï¸ pytest.ini                    # PyTest configuration
â”œâ”€â”€ ğŸ” .env                          # Environment variables
â”œâ”€â”€ ğŸ“§ EMAIL_SETUP.md                # Email alert configuration
â””â”€â”€ ğŸ“– README.md                     # This file
```

## ğŸ¨ **Portfolio Components**

### **ğŸŒŸ Star Schema Diagrams**
- **Professional Visualizations**: PNG diagrams for presentations
- **GitHub Integration**: Mermaid diagrams for repositories
- **Custom Generation**: Python script for modifications
- **Complete Documentation**: Usage guides and examples

### **ğŸ¨ Qlik Sense Dashboard**
- **Complete Setup Guide**: Step-by-step implementation
- **Advanced Calculations**: Sophisticated business metrics
- **Visual Mockups**: Professional dashboard layouts
- **Portfolio Ready**: Documentation and examples

### **ğŸ“Š Airflow DAG Visualizations**
- **Professional Graphs**: PNG images of all DAGs
- **Portfolio Showcase**: Visual representation of orchestration
- **Graphviz Integration**: High-quality diagram generation
- **Complete Coverage**: All 6 DAGs visualized

### **ğŸ“§ Email Alert System**
- **SMTP Configuration**: Professional notification setup
- **Master DAG Integration**: Automated pipeline monitoring
- **Portfolio Demonstration**: Real-world alerting system

## ğŸš€ **Quick Start**

### **1. Environment Setup**
```bash
# Clone repository
git clone <your-repo-url>
cd ad_campaign_spend_tracker

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-test.txt
```

### **2. Snowflake Configuration**
```bash
# Copy environment template
cp .env.example .env

# Edit .env with your Snowflake credentials
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_USER=your_username
SNOWFLAKE_PROGRAMMATIC_TOKEN=your_token
SNOWFLAKE_DATABASE=AD_CAMPAIGNS
SNOWFLAKE_SCHEMA=RAW
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
```

### **3. Data Pipeline Execution**
```bash
# Generate and load initial data
python scripts/generate_backfill_ads.py
python scripts/load_backfill_to_snowflake.py

# Run daily pipeline
python scripts/generate_fake_ads.py
python scripts/load_daily_snowflake.py
```

### **4. Data Transformation**
```bash
# Navigate to dbt directory
cd dbt

# Install dbt dependencies
dbt deps

# Run transformations
dbt run

# Generate documentation
dbt docs generate
dbt docs serve
```

### **5. Run Analytics**
```bash
# Execute portfolio showcase queries
python run_portfolio_queries.py
```

## ğŸ§ª **Testing & Quality Assurance**

### **PyTest Test Suite**
```bash
# Run all tests
python run_tests.py

# Run specific test file
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ --cov=scripts --cov=dbt --cov-report=html
```

### **Great Expectations Validation**
```bash
# Run data quality validation
python great_expectations/validate_ad_data.py
```

### **Test Coverage**
- **Data Generation**: 10 comprehensive tests
- **Business Logic**: Data quality rules validation
- **Data Types**: Schema validation
- **Value Ranges**: Business rule enforcement
- **Coverage Target**: 80%+ code coverage

## ğŸ“Š **Data Model**

### **Kimball Star Schema**
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Fact Tables   â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ fact_ad_      â”‚
                    â”‚   performance   â”‚
                    â”‚ â€¢ mart_campaign_â”‚
                    â”‚   performance   â”‚
                    â”‚ â€¢ mart_platform_â”‚
                    â”‚   performance   â”‚
                    â”‚ â€¢ mart_daily_   â”‚
                    â”‚   performance   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dimensions  â”‚    â”‚ Dimensions  â”‚    â”‚ Dimensions  â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â”‚ â€¢ dim_      â”‚    â”‚ â€¢ dim_      â”‚    â”‚ â€¢ dim_      â”‚
â”‚   platforms â”‚    â”‚   geography â”‚    â”‚   dates     â”‚
â”‚ â€¢ dim_      â”‚    â”‚ â€¢ dim_      â”‚    â”‚ â€¢ dim_      â”‚
â”‚   campaigns â”‚    â”‚   devices   â”‚    â”‚   ad_formatsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” **Data Quality & Validation**

### **Great Expectations Suite**
- **Schema Validation**: Column presence, data types
- **Business Rules**: CTR â‰¤ 100%, impressions â‰¥ clicks
- **Value Ranges**: Reasonable spend, impression limits
- **Data Integrity**: Unique constraints, referential integrity

### **Automated Testing**
- **Unit Tests**: Function behavior validation
- **Integration Tests**: End-to-end pipeline testing
- **Data Quality Tests**: Business rule enforcement
- **Performance Tests**: Pipeline efficiency validation

## ğŸ“ˆ **Business Intelligence**

### **Key Metrics**
- **CTR (Click-Through Rate)**: Click performance
- **CPC (Cost Per Click)**: Cost efficiency
- **CVR (Conversion Rate)**: Conversion performance
- **ROAS (Return on Ad Spend)**: ROI measurement
- **CPM (Cost Per Mille)**: Impression cost

### **Analytics Capabilities**
- **Platform Performance**: Cross-platform comparison
- **Geographic Analysis**: Market performance insights
- **Campaign Effectiveness**: Objective-based analysis
- **Time Series Analysis**: Trend identification
- **Device Performance**: Cross-device optimization

## ğŸš€ **Portfolio Value**

### **Technical Skills Demonstrated**
- **Data Engineering**: ETL/ELT pipeline development
- **Cloud Platforms**: Snowflake data warehouse
- **Orchestration**: Apache Airflow workflow management
- **Data Modeling**: Kimball star schema design
- **Testing**: Comprehensive test automation
- **Documentation**: Professional project documentation

### **Business Understanding**
- **Marketing Analytics**: Ad campaign performance metrics
- **Data Quality**: Production-ready validation
- **Performance Optimization**: Efficient data processing
- **Scalability**: Cloud-native architecture
- **Monitoring**: Pipeline health tracking

## ğŸ”® **Future Enhancements**

### **Phase 4: Advanced Analytics**
- [ ] **Tableau Integration**: Interactive dashboards
- [ ] **Machine Learning**: Predictive analytics
- [ ] **Real-time Processing**: Streaming data pipeline
- [ ] **Advanced Testing**: Performance benchmarking

### **Phase 5: Production Features**
- [ ] **CI/CD Pipeline**: Automated deployment
- [ ] **Monitoring**: Advanced alerting & metrics
- [ ] **Security**: Role-based access control
- [ ] **Compliance**: GDPR, CCPA compliance

## ğŸ“š **Documentation Resources**

- **dbt Documentation**: `dbt docs serve` (http://localhost:8080)
- **Project Summary**: [PORTFOLIO_SUMMARY.md](docs/PORTFOLIO_SUMMARY.md)
- **Code Coverage**: `htmlcov/index.html`
- **Test Results**: `pytest` output with coverage

## ğŸ¤ **Contributing**

This is a portfolio project demonstrating data engineering skills. For questions or feedback:

1. **Review the code**: All scripts are well-documented
2. **Run the tests**: Ensure quality with `python run_tests.py`
3. **Explore the data**: Use `run_portfolio_queries.py`
4. **Check documentation**: `dbt docs serve`

## ğŸ“„ **License**

This project is created for portfolio demonstration purposes. Feel free to use as a reference for your own projects.

---

## ğŸ¯ **Portfolio Showcase**

### **What This Project Demonstrates**
- **Data Engineering Excellence**: Complete end-to-end pipeline
- **Professional Architecture**: Kimball methodology implementation
- **Modern Technology Stack**: Latest tools and best practices
- **Production Readiness**: Testing, monitoring, and documentation
- **Business Intelligence**: Real-world analytics and insights
- **Visual Communication**: Professional diagrams and documentation


